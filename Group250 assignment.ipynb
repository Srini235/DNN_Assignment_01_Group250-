{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Srini235/DNN_Assignment_01_Group250-/blob/main/Group250%20assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64-XCLdSBBuc"
   },
   "source": [
    "# Deep Neural Networks - Programming Assignment\n",
    "## Comparing Linear Models and Multi-Layer Perceptrons\n",
    "\n",
    "**Student Name:** Srinivasan R  \n",
    "**Student ID:** 2024AC05744  \n",
    "\n",
    "**Student Name:** Manodhayan K  \n",
    "**Student ID:** ___________________  \n",
    "\n",
    "**Student Name:** Ankit Saxena  \n",
    "**Student ID:** ___________________  \n",
    "\n",
    "**Student Name:** Vinu Abinayaa R  \n",
    "**Student ID:** ___________________  \n",
    "\n",
    "**Date:** ___________________\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT INSTRUCTIONS\n",
    "\n",
    "1. **Complete ALL sections** marked with `TODO`\n",
    "2. **DO NOT modify** the `get_assignment_results()` function structure\n",
    "3. **Track training time** for both models using `time.time()`\\n\n",
    "4. **Store loss_history** in both model classes\n",
    "5. **Calculate ALL metrics** (accuracy, precision, recall, F1)\n",
    "6. **Fill get_assignment_results()** with ALL required fields\n",
    "7. **PRINT the results** - Auto-grader needs visible output!\n",
    "8. **Run all cells** before submitting (Kernel ‚Üí Restart & Run All)\n",
    "\n",
    "**SCORING:**\n",
    "- Missing fields = 0 marks for that section\n",
    "- Non-executed notebook = 0 marks\n",
    "- Cleared outputs = 0 marks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Pti5nJuBBue"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn import datasets\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "print('Libraries imported successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNyOCAuwBBue"
   },
   "source": [
    "## Section 1: Dataset Selection and Loading\n",
    "\n",
    "**Requirements:**\n",
    "- ‚â•500 samples\n",
    "- ‚â•5 features\n",
    "- Public dataset (UCI/Kaggle)\n",
    "- Regression OR Classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QfsHoIkBBuf"
   },
   "outputs": [],
   "source": [
    "# TODO: Load your dataset\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891)\n",
    "\n",
    "# data (as pandas dataframes) \n",
    "x = cdc_diabetes_health_indicators.data.features \n",
    "y = cdc_diabetes_health_indicators.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(cdc_diabetes_health_indicators.metadata) \n",
    "\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "# Dataset information (TODO: Fill these)\n",
    "dataset_name = \"CDC Diabetes Health Indicators\"  # e.g., \"Breast Cancer Wisconsin\"\n",
    "dataset_source = \"UCI ML Repository\"  # e.g., \"UCI ML Repository\"\n",
    "n_samples = 253680      # Total number of rows\n",
    "n_features = x.shape[1]     # Number of features (excluding target)\n",
    "problem_type = \"binary_classification\"  # \"regression\" or \"binary_classification\" or \"multiclass_classification\"\n",
    "\n",
    "# Problem statement (TODO: Write 2-3 sentences)\n",
    "problem_statement = \"\"\"\n",
    "Predicting diabetes health indicators from patient data.\n",
    "This is critical for early intervention and management of diabetes in healthcare settings.\n",
    "\"\"\"\n",
    "\n",
    "# Primary evaluation metric (TODO: Fill this)\n",
    "primary_metric = \"recall\"  # e.g., \"recall\", \"accuracy\", \"rmse\", \"r2\"\n",
    "# Metric justification (TODO: Write 2-3 sentences)\n",
    "metric_justification = \"\"\"\n",
    "I chose recall because in medical diagnosis,\n",
    "false negatives (missing diabetes cases) are more costly than false positives.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Source: {dataset_source}\")\n",
    "print(f\"Samples: {n_samples}, Features: {n_features}\")\n",
    "print(f\"Problem Type: {problem_type}\")\n",
    "print(f\"Primary Metric: {primary_metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XOI6I6JBBuf"
   },
   "source": [
    "## Section 2: Data Preprocessing\n",
    "\n",
    "Preprocess your data:\n",
    "1. Handle missing values\n",
    "2. Encode categorical variables\n",
    "3. Split into train/test sets\n",
    "4. Scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfQProeUBBuf"
   },
   "outputs": [],
   "source": [
    "# TODO: Preprocess your data\n",
    "# 1. Separate features (X) and target (y)\n",
    "print(f\"Original y shape: {y.shape}\")\n",
    "y = y.flatten()\n",
    "print(f\"Flattened y shape: {y.shape}\")\n",
    "\n",
    "\n",
    "# 2. Handle missing values if any\n",
    "# Data integrity check\n",
    "print(f\"\\nData integrity check:\")\n",
    "print(f\"  X shape: {x.shape}\")\n",
    "print(f\"  y shape: {y.shape}\")\n",
    "print(f\"  Data loaded successfully\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nClass distribution:\")\n",
    "unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    pct = 100 * count / len(y)\n",
    "    print(f\"  Class {int(cls)}: {count:,} samples ({pct:.1f}%)\")\n",
    "\n",
    "# 3. Encode categorical variables if any \n",
    "# (not needed here as data is numeric)\n",
    "\n",
    "# TODO: Train-test split (with stratification)\n",
    "# Step 1: Split into train+val and test sets (e.g., 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Split train+val into train and validation sets (e.g., 25% of train_val for validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val\n",
    ")\n",
    "# 0.25 of 80% = 20%\n",
    "# i.e., Final split is 60% train, 20% val, 20% test\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}, Test size: {len(X_test)}\")\n",
    "\n",
    "# Compute class weights to handle class imbalance\n",
    "print(\"\\n1. Computing class weights for imbalanced data...\")\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"   Class weights: {class_weight_dict}\")\n",
    "print(f\"   (Minority class has higher weight to compensate for imbalance)\")\n",
    "\n",
    "# TODO: Feature scaling\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"   Scaling complete. Feature means: {X_train_scaled.mean(axis=0)[:3]}...\")\n",
    "\n",
    "# Fill these after preprocessing\n",
    "train_samples = len(y_train)       # Number of training samples\n",
    "test_samples = len(y_test)        # Number of test samples\n",
    "train_test_ratio = 0.8  # e.g., 0.8 for 80-20 split\n",
    "\n",
    "print(f\"\\n‚úì Preprocessing complete!\")\n",
    "print(f\"Train samples: {train_samples}\")\n",
    "print(f\"Test samples: {test_samples}\")\n",
    "print(f\"Split ratio: {train_test_ratio:.1%}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Elw6-stdBBuf"
   },
   "source": [
    "## Section 3: Baseline Model Implementation\n",
    "\n",
    "Implement from scratch (NO sklearn models!):\n",
    "- Linear Regression (for regression)\n",
    "- Logistic Regression (for binary classification)\n",
    "- Softmax Regression (for multiclass classification)\n",
    "\n",
    "**Must include:**\n",
    "- Forward pass (prediction)\n",
    "- Loss computation\n",
    "- Gradient computation\n",
    "- Gradient descent loop\n",
    "- Loss tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvQ2rWfWBBuf"
   },
   "outputs": [],
   "source": [
    "class BaselineModel:\n",
    "    \"\"\"\n",
    "    Baseline linear model with Stochastic Gradient Descent (SGD)\n",
    "    Implements: Logistic Regression for binary classification\n",
    "    Updates weights after each individual sample (true SGD)\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        TODO: Implement gradient descent training\n",
    "\n",
    "        Steps:\n",
    "        1. Initialize weights and bias\n",
    "        2. For each iteration:\n",
    "           a. Compute predictions (forward pass)\n",
    "           b. Compute loss\n",
    "           c. Compute gradients\n",
    "           d. Update weights and bias\n",
    "           e. Store loss in self.loss_history\n",
    "\n",
    "        Must populate self.loss_history with loss at each iteration!\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Xavier initialization for binary classification\n",
    "        limit = np.sqrt(6 / (n_features + 1))\n",
    "        self.weights = np.random.uniform(-limit, limit, n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # SGD: Update weights after each sample\n",
    "        for epoch in range(self.n_iterations):\n",
    "            # Shuffle data at the beginning of each epoch\n",
    "            indices = np.arange(n_samples)\n",
    "            np.random.shuffle(indices)\n",
    "            X_shuffled = X[indices]\n",
    "            y_shuffled = y[indices]\n",
    "            \n",
    "            # Process each sample individually (Stochastic)\n",
    "            for sample_idx in range(n_samples):\n",
    "                # Get single sample\n",
    "                x_sample = X_shuffled[sample_idx]\n",
    "                y_sample = y_shuffled[sample_idx]\n",
    "                \n",
    "                # Forward pass (single sample): z = w*x + b\n",
    "                z = np.dot(x_sample, self.weights) + self.bias\n",
    "                \n",
    "                # Sigmoid activation\n",
    "                y_pred = self.sigmoid(z)\n",
    "                \n",
    "                # Compute binary cross-entropy loss (single sample)\n",
    "                eps = 1e-12\n",
    "                y_pred = np.clip(y_pred, eps, 1 - eps)\n",
    "                loss = -(y_sample * np.log(y_pred) + (1 - y_sample) * np.log(1 - y_pred))\n",
    "                self.loss_history.append(loss)\n",
    "                \n",
    "                # Backward pass: compute gradients\n",
    "                error = y_pred - y_sample  # Derivative of sigmoid cross-entropy\n",
    "                dw = error * x_sample      # Gradient w.r.t weights\n",
    "                db = error                  # Gradient w.r.t bias\n",
    "                \n",
    "                # Update parameters (single sample update - SGD characteristic)\n",
    "                self.weights -= self.lr * dw\n",
    "                self.bias -= self.lr * db\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def sigmoid(self, Z):\n",
    "        \"\"\"Sigmoid activation for binary classification\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(Z, -500, 500)))\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Predict binary class labels for binary classification\n",
    "        \n",
    "        For each sample in X:\n",
    "            1. Compute z = w*x + b\n",
    "            2. Apply sigmoid: output in [0, 1]\n",
    "            3. Apply threshold: if output >= threshold, predict 1, else 0\n",
    "        \n",
    "        Args:\n",
    "            X: Input features (n_samples, n_features)\n",
    "            threshold: Decision boundary (default 0.5)\n",
    "        \n",
    "        Returns:\n",
    "            Binary predictions (0 or 1) for each sample\n",
    "        \"\"\"\n",
    "        if self.weights is None or self.bias is None:\n",
    "            raise RuntimeError(\"Model has not been trained yet. Call .fit() first.\")\n",
    "        \n",
    "        # Compute logits for all samples\n",
    "        z = np.dot(X, self.weights) + self.bias\n",
    "        \n",
    "        # Apply sigmoid\n",
    "        y_pred = self.sigmoid(z)\n",
    "        \n",
    "        # Apply threshold for binary classification\n",
    "        return (y_pred >= threshold).astype(int)\n",
    "\n",
    "print(\"‚úì Baseline model class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grpLqkmTBBuf"
   },
   "outputs": [],
   "source": [
    "# Train baseline model\n",
    "print(\"Training baseline model...\")\n",
    "baseline_start = time.time()\n",
    "\n",
    "# Convert multiclass to binary classification (class 0 vs all others)\n",
    "# Negative class (0): original class 0\n",
    "# Positive class (1): original classes 1, 2, ...\n",
    "y_train_binary = (y_train > 0).astype(int)\n",
    "y_test_binary = (y_test > 0).astype(int)\n",
    "\n",
    "print(f\"Binary classification: class 0 (negative) vs classes 1,2 (positive)\")\n",
    "print(f\"Training samples - Negative: {np.sum(y_train_binary == 0)}, Positive: {np.sum(y_train_binary == 1)}\")\n",
    "print(f\"Test samples - Negative: {np.sum(y_test_binary == 0)}, Positive: {np.sum(y_test_binary == 1)}\")\n",
    "\n",
    "# Initialize and train baseline model with SGD\n",
    "baseline_model = BaselineModel(learning_rate=0.01, n_iterations=100)\n",
    "baseline_model.fit(X_train_scaled, y_train_binary)\n",
    "\n",
    "# TODO: Make predictions\n",
    "baseline_predictions = baseline_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "baseline_training_time = time.time() - baseline_start\n",
    "print(f\"‚úì Baseline training completed in {baseline_training_time:.2f}s\")\n",
    "print(f\"‚úì Loss decreased from {baseline_model.loss_history[0]:.4f} to {baseline_model.loss_history[-1]:.4f}\")\n",
    "print(f\"‚úì Total loss updates: {len(baseline_model.loss_history)} (one per sample per epoch)\")\n",
    "\n",
    "# Store loss explicitly\n",
    "baseline_initial_loss = baseline_model.loss_history[0]\n",
    "baseline_final_loss = baseline_model.loss_history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQpy-zZSBBug"
   },
   "source": [
    "## Section 4: Multi-Layer Perceptron Implementation\n",
    "\n",
    "Implement MLP from scratch with:\n",
    "- At least 1 hidden layer\n",
    "- ReLU activation for hidden layers\n",
    "- Appropriate output activation\n",
    "- Forward propagation\n",
    "- Backward propagation\n",
    "- Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2wqZVlfBBug"
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \"\"\"\n",
    "    Multi-Layer Perceptron implemented from scratch\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture, learning_rate=0.01, n_iterations=1000):\n",
    "        \"\"\"\n",
    "        architecture: list [input_size, hidden1, hidden2, ..., output_size]\n",
    "        Example: [30, 16, 8, 1] means:\n",
    "            - 30 input features\n",
    "            - Hidden layer 1: 16 neurons\n",
    "            - Hidden layer 2: 8 neurons\n",
    "            - Output layer: 1 neuron\n",
    "        \"\"\"\n",
    "        self.architecture = architecture\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.parameters = {}\n",
    "        self.loss_history = []\n",
    "        self.cache = {}\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \"\"\"\n",
    "        TODO: Initialize weights and biases for all layers\n",
    "\n",
    "        For each layer l:\n",
    "        - W[layer_index]: weight matrix of shape (n[layer_index], n[layer_index-1])\n",
    "        - b[layer_index]: bias vector of shape (n[layer_index], 1)\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "\n",
    "        for layer_index in range(1, len(self.architecture)):\n",
    "            num_perceptrons_current = self.architecture[layer_index]\n",
    "            num_perceptrons_previous = self.architecture[layer_index-1]\n",
    "            # Weights\n",
    "            # # He init for hidden layers; Xavier-ish for output\n",
    "            # if layer_index < len(self.architecture) - 1:\n",
    "            #     self.parameters[f'W{layer_index}'] = np.random.randn(num_perceptrons_current, num_perceptrons_previous) \\\n",
    "            #         * np.sqrt(2/num_perceptrons_previous)\n",
    "            # else:\n",
    "            #     self.parameters[f'W{layer_index}'] = np.random.randn(num_perceptrons_current, num_perceptrons_previous) \\\n",
    "            #         * np.sqrt(1/num_perceptrons_previous)\n",
    "            self.parameters[f'W{layer_index}'] = np.zeros((num_perceptrons_current, num_perceptrons_previous))\n",
    "            # print(f'W{layer_index}: {self.parameters[f'W{layer_index}'].shape}')\n",
    "\n",
    "            # Bias\n",
    "            self.parameters[f'b{layer_index}'] = np.zeros((num_perceptrons_current, 1))\n",
    "            # print(f'b{layer_index}: {self.parameters[f'b{layer_index}'].shape}')\n",
    "\n",
    "\n",
    "\n",
    "    def relu(self, Z):\n",
    "        \"\"\"ReLU activation function\"\"\"\n",
    "        return np.maximum(0, Z)\n",
    "\n",
    "    def relu_derivative(self, Z):\n",
    "        \"\"\"ReLU derivative\"\"\"\n",
    "        return (Z > 0).astype(float)\n",
    "\n",
    "    def sigmoid(self, Z):\n",
    "        \"\"\"Sigmoid activation (for binary classification output)\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(Z, -500, 500)))\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        \"\"\"\n",
    "        TODO: Implement forward pass through all layers\n",
    "\n",
    "        For each layer:\n",
    "        1. Z[l] = W[l] @ A[l-1] + b[l]\n",
    "        2. A[l] = activation(Z[l])\n",
    "\n",
    "        Store Z and A in self.cache for backpropagation\n",
    "        Return final activation A[L]\n",
    "        \"\"\"\n",
    "        fc_in = X.T\n",
    "        self.cache['A0'] = fc_in\n",
    "        num_layers = len(self.architecture) - 1\n",
    "        for layer_index in range(1, num_layers + 1):\n",
    "            weight, bias = self.parameters[f'W{layer_index}'], self.parameters[f'b{layer_index}']\n",
    "            fc_out = np.dot(weight, fc_in) + bias\n",
    "            activation = self.relu(fc_out) if layer_index < num_layers else self.sigmoid(fc_out)\n",
    "            self.cache[f'Z{layer_index}'] = fc_out\n",
    "            self.cache[f'A{layer_index}'] = activation\n",
    "            fc_in = activation\n",
    "        \n",
    "        final_layer_activation = activation\n",
    "        return final_layer_activation\n",
    "\n",
    "        # TODO: Implement forward pass\n",
    "        # for l in range(1, len(self.architecture)):\n",
    "        #     ...\n",
    "\n",
    "    def backward_propagation(self, y):\n",
    "        grads = {}\n",
    "        num_samples = y.shape[0]\n",
    "        num_layers = len(self.architecture) - 1\n",
    "        activation = self.cache[f'A{num_layers}'] \n",
    "        previous_layer_activation = self.cache[f'A{num_layers-1}'] if num_layers-1 >= 0 else self.cache['A0']\n",
    "        dZ_L = (activation - y.reshape(1, num_samples))         \n",
    "        grads[f'dW{num_layers}'] = (1/num_samples) * np.dot(dZ_L, previous_layer_activation.T)\n",
    "        grads[f'db{num_layers}'] = (1/num_samples) * np.sum(dZ_L, axis=1, keepdims=True)\n",
    "\n",
    "        for layer_index in range(num_layers-1, 0, -1):\n",
    "            W_next = self.parameters[f'W{layer_index+1}']\n",
    "            dZ_next = dZ_L if layer_index == num_layers-1 else grads[f'dZ{layer_index+1}']\n",
    "            previous_layer_activation = self.cache[f'A{layer_index-1}'] if layer_index-1 >= 0 else self.cache['A0']\n",
    "            Z_l = self.cache[f'Z{layer_index}']\n",
    "            dA_l = np.dot(W_next.T, dZ_next)\n",
    "            dZ_l = dA_l * self.relu_derivative(Z_l)\n",
    "            grads[f'dZ{layer_index}'] = dZ_l\n",
    "            grads[f'dW{layer_index}'] = (1/num_samples) * np.dot(dZ_l, previous_layer_activation.T)\n",
    "            grads[f'db{layer_index}'] = (1/num_samples) * np.sum(dZ_l, axis=1, keepdims=True)\n",
    "        return grads\n",
    "\n",
    "    def update_parameters(self, grads):\n",
    "        for layer_index in range(1, len(self.architecture)):\n",
    "            self.parameters[f'W{layer_index}'] -= self.lr * grads[f'dW{layer_index}']\n",
    "            self.parameters[f'b{layer_index}'] -= self.lr * grads[f'db{layer_index}']\n",
    "\n",
    "\n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "       m = y_true.shape[0]\n",
    "       eps = 1e-12\n",
    "       y_pred = np.clip(y_pred.flatten(), eps, 1-eps)\n",
    "       return -(1/m) * np.sum(y_true*np.log(y_pred) + (1-y_true)*np.log(1-y_pred))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        For each iteration:\n",
    "        1. Forward propagation\n",
    "        2. Compute loss\n",
    "        3. Backward propagation\n",
    "        4. Update parameters\n",
    "        5. Store loss\n",
    "\n",
    "        Must populate self.loss_history!\n",
    "        \"\"\"\n",
    "        self.initialize_parameters()\n",
    "\n",
    "        for i in range(self.n_iterations):\n",
    "            A_L = self.forward_propagation(X)\n",
    "            loss = self.compute_loss(A_L, y)\n",
    "            grads = self.backward_propagation(y)\n",
    "            self.update_parameters(grads)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Use forward_propagation and apply appropriate thresholding\n",
    "        \"\"\"\n",
    "        prediction = self.forward_propagation(X).flatten()\n",
    "        return (prediction >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foCVrsiTBBug"
   },
   "outputs": [],
   "source": [
    "# Train MLP\n",
    "print(\"Training MLP...\")\n",
    "mlp_start_time = time.time()\n",
    "\n",
    "mlp_architecture = [n_features, 16, 8, 1]  \n",
    "mlp_model = MLP(architecture=mlp_architecture, learning_rate=0.001, n_iterations=10000)\n",
    "mlp_model.fit(X_train_scaled , y_train)\n",
    "\n",
    "mlp_predictions = mlp_model.predict(X_test_scaled, threshold=0.35)\n",
    "\n",
    "mlp_training_time = time.time() - mlp_start_time\n",
    "print(f\"MLP training completed in {mlp_training_time:.2f}s\")\n",
    "print(f\"Loss decreased from {mlp_model.loss_history[0]:.4f} to {mlp_model.loss_history[-1]:.4f}\")\n",
    "\n",
    "# Store loss explicitly\n",
    "mlp_initial_loss = mlp_model.loss_history[0]\n",
    "mlp_final_loss = mlp_model.loss_history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bf38UvC0BBug"
   },
   "source": [
    "## Section 5: Evaluation and Metrics\n",
    "\n",
    "Calculate appropriate metrics for your problem type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dei5PjKGBBug"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, problem_type):\n",
    "    \"\"\"\n",
    "    TODO: Calculate appropriate metrics based on problem type\n",
    "\n",
    "    For regression: MSE, RMSE, MAE, R¬≤\n",
    "    For classification: Accuracy, Precision, Recall, F1\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    if problem_type == \"regression\":\n",
    "        # TODO: Calculate regression metrics\n",
    "        # TODO: Implement from scratch\n",
    "        mse = np.mean((y_true - y_pred) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        \n",
    "        # R¬≤ = 1 - (SS_res / SS_tot)\n",
    "        ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0\n",
    "        \n",
    "        return mse, rmse, mae, r2\n",
    "        \n",
    "    elif problem_type in [\"binary_classification\", \"multiclass_classification\"]:\n",
    "        # TODO: Calculate classification metrics\n",
    "        # TODO: Implement from scratch (no sklearn.metrics)\n",
    "        \n",
    "        # Accuracy: (correct predictions) / (total predictions)\n",
    "        accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "        \n",
    "        # For multiclass: macro-averaged precision, recall, and F1\n",
    "        classes = np.unique(y_true)\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for cls in classes:\n",
    "            # True positives: predicted as this class AND actually this class\n",
    "            tp = np.sum((y_pred == cls) & (y_true == cls))\n",
    "            # False positives: predicted as this class but actually different\n",
    "            fp = np.sum((y_pred == cls) & (y_true != cls))\n",
    "            # False negatives: not predicted as this class but actually this class\n",
    "            fn = np.sum((y_pred != cls) & (y_true == cls))\n",
    "            \n",
    "            # Precision: TP / (TP + FP)\n",
    "            precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "            precisions.append(precision)\n",
    "            \n",
    "            # Recall: TP / (TP + FN)\n",
    "            recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "            recalls.append(recall)\n",
    "            \n",
    "            # F1: 2 * (precision * recall) / (precision + recall)\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        # Macro-average (average across all classes)\n",
    "        precision = np.mean(precisions)\n",
    "        recall = np.mean(recalls)\n",
    "        f1 = np.mean(f1_scores)\n",
    "        \n",
    "        return accuracy, precision, recall, f1\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for both models\n",
    "# Use binary labels for baseline, original labels for MLP (if still multiclass)\n",
    "baseline_metrics = [baseline_acc, baseline_prec, baseline_rec, baseline_f1] = calculate_metrics(y_test_binary, baseline_predictions, \"binary_classification\")\n",
    "mlp_metrics = [mlp_acc, mlp_prec, mlp_rec, mlp_f1] = calculate_metrics(y_test, mlp_predictions, problem_type)\n",
    "\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Baseline Model Performance (Binary Classification):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Accuracy: {baseline_acc:.4f}\")\n",
    "print(f\"  Precision: {baseline_prec:.4f}\")\n",
    "print(f\"  Recall: {baseline_rec:.4f}\")\n",
    "print(f\"  F1-Score: {baseline_f1:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"MLP Model Performance ({problem_type}):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"  Accuracy: {mlp_acc:.4f}\")\n",
    "print(f\"  Precision: {mlp_prec:.4f}\")\n",
    "print(f\"  Recall: {mlp_rec:.4f}\")\n",
    "print(f\"  F1-Score: {mlp_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4SZCkf3BBug"
   },
   "source": [
    "## Section 6: Visualization\n",
    "\n",
    "Create visualizations:\n",
    "1. Training loss curves\n",
    "2. Performance comparison\n",
    "3. Additional domain-specific plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPqji5F0BBuh"
   },
   "outputs": [],
   "source": [
    "# 1. Training loss curves\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "# TODO: Plot baseline loss\n",
    "plt.plot(baseline_model.loss_history, label='Baseline', color='blue')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Baseline Model - Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# TODO: Plot MLP loss\n",
    "plt.plot(mlp_model.loss_history, label='MLP', color='red')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MLP Model - Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6Pj6pQZBBuh"
   },
   "outputs": [],
   "source": [
    "# 2. Performance comparison bar chart\n",
    "# TODO: Create bar chart comparing key metrics between models\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create comparison using the unpacked metric variables\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "baseline_scores = [baseline_acc, baseline_prec, baseline_rec, baseline_f1]\n",
    "mlp_scores = [mlp_acc, mlp_prec, mlp_rec, mlp_f1]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, baseline_scores, width, label='Baseline')\n",
    "plt.bar(x + width/2, mlp_scores, width, label='MLP')\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x, metrics_names)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua107rhpBBuh"
   },
   "source": [
    "## Section 7: Analysis and Discussion\n",
    "\n",
    "Write your analysis (minimum 200 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fdNLJqCBBuh"
   },
   "outputs": [],
   "source": [
    "analysis_text = \"\"\"\n",
    "1. Which model performed better overall?\n",
    "‚Ä¢ Baseline (Softmax): Accuracy 64.34%, Precision 61.42%, Recall 73.65%, F1 0.5746\n",
    "‚Ä¢ MLP Model: Accuracy 86.07%, Precision 43.03%, Recall 50.00%, F1 0.4626\n",
    "‚Ä¢ The MLP achieved 21.73% higher accuracy‚Äîa significant improvement for overall classification performance\n",
    "‚Ä¢ However, the baseline model achieved superior precision (18.39% higher) and recall (23.65% higher), making it better at identifying positive cases\n",
    "\n",
    "**2. Why Performance Differed:**\n",
    "‚Ä¢ The dataset is imbalanced (86.1% negative vs 13.9% positive class)‚ÄîMLP's higher accuracy masks poor minority class detection\n",
    "‚Ä¢ Softmax regression, being linear, captures class separability efficiently for this imbalanced problem\n",
    "‚Ä¢ MLP likely overfits to majority class despite dropout/regularization limitations in the implementation\n",
    "‚Ä¢ The baseline's higher recall (0.7365) proves crucial for medical diagnosis where false negatives are costly\n",
    "‚Ä¢ MLP's architecture [21‚Üí16‚Üí4‚Üí1] may be insufficient to model complex non-linear patterns in this dataset\n",
    "\n",
    "**3. Computational Cost Difference:**\n",
    "‚Ä¢ Baseline training time: 0.18 seconds‚Äîextremely efficient\n",
    "‚Ä¢ MLP training time: 68.77 seconds‚Äî382√ó slower than baseline\n",
    "‚Ä¢ This massive computational gap reflects MLP's complexity: forward/backward propagation across multiple layers, matrix multiplications, and 1000 iterations\n",
    "‚Ä¢ For production systems with real-time constraints, baseline's speed is a critical advantage\n",
    "\n",
    "**4. Surprising Findings & Challenges:**\n",
    "‚Ä¢ Counter-intuitive result: simpler model outperformed complex model on primary metric (recall)\n",
    "‚Ä¢ Challenge: MLP's convergence with random initialization‚Äîloss decreased but metrics suffered\n",
    "‚Ä¢ Imbalanced dataset dominance‚Äîaccuracy alone misled performance evaluation; F1 score revealed the true story\n",
    "‚Ä¢ The baseline's loss dropped from 0.9782‚Üí0.6769, while MLP went 0.6931‚Üí0.4038, yet baseline had better generalization\n",
    "\n",
    "**5. Key Insights:**\n",
    "‚Ä¢ Complexity ‚â† Performance: Linear models can outshine neural networks on appropriately-scaled problems\n",
    "‚Ä¢ Model selection must consider domain context‚Äîfor medical diagnosis, recall is paramount; baseline's 0.7365 recall saved patients\n",
    "‚Ä¢ Computational efficiency matters: 382√ó speedup enables real-time deployment\n",
    "‚Ä¢ Data imbalance requires careful metric selection‚Äîaccuracy is misleading; precision-recall trade-offs dominate medical AI\n",
    "‚Ä¢ Deep learning's advantage emerges with high-dimensional non-linear patterns; low-dimensional healthcare data favors simpler approaches\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Analysis word count: {len(analysis_text.split())} words\")\n",
    "if len(analysis_text.split()) < 200:\n",
    "    print(\"‚ö†Ô∏è  Warning: Analysis should be at least 200 words\")\n",
    "else:\n",
    "    print(\"‚úì Analysis meets word count requirement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e3C2Bf4BBuh"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## ‚≠ê REQUIRED: Structured Output Function\n",
    "\n",
    "### **DO NOT MODIFY THE STRUCTURE BELOW**\n",
    "\n",
    "This function will be called by the auto-grader. Fill in all values accurately based on your actual results.\n",
    "\n",
    "\n",
    "‚≠ê‚≠ê‚≠ê REQUIRED: Structured Output Function ‚≠ê‚≠ê‚≠ê\n",
    "\n",
    "### üö® CRITICAL - READ CAREFULLY üö®\n",
    "\n",
    "1. **Fill in ALL fields** - Missing fields = 0 marks\n",
    "2. **Use your actual values** - Not 0 or empty strings\n",
    "3. **This cell MUST be executed** - We need the output!\n",
    "4. **Print the results** - Auto-grader needs to see output!\n",
    "\n",
    "\n",
    "**DO NOT:**\n",
    "- Leave any field as 0, 0.0,\n",
    "- Clear outputs before submission\n",
    "- Modify the structure\n",
    "\n",
    "\n",
    "\"**MUST DO:**\n",
    "- Fill every field with your actual results\n",
    "- Execute this cell and keep the output\n",
    "- Print the results (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1W6qvYzBBuh"
   },
   "outputs": [],
   "source": [
    "def get_assignment_results():\n",
    "    '''\n",
    "    CRITICAL: Fill ALL fields with your actual results!\n",
    "    Missing fields will result in 0 marks for that section.\n",
    "    '''\n",
    "\n",
    "    results = {\n",
    "        # ===== Dataset Information (1 mark) =====\n",
    "        'dataset_name': dataset_name,  # MUST fill\n",
    "        'dataset_source': dataset_source,  # MUST fill\n",
    "        'n_samples': int(n_samples),  # MUST be ‚â•500\n",
    "        'n_features': int(n_features),  # MUST be ‚â•5\n",
    "        'problem_type': problem_type,  # MUST fill\n",
    "        'problem_statement': problem_statement,  # MUST be ‚â•50 words\n",
    "        'primary_metric': primary_metric,  # MUST fill\n",
    "        'metric_justification': metric_justification,  # MUST be ‚â•30 words\n",
    "        'train_samples': int(train_samples),\n",
    "        'test_samples': int(test_samples),\n",
    "        'train_test_ratio': float(train_test_ratio),\n",
    "\n",
    "        # ===== Baseline Model (3 marks) =====\n",
    "        'baseline_model': {\n",
    "            'model_type': 'softmax_regression',  # 'linear_regression', 'logistic_regression', 'softmax_regression'\n",
    "            'learning_rate': 0.01,  # Your learning rate\n",
    "            'n_iterations': 1000,  # Your iterations\n",
    "\n",
    "            # CRITICAL: These MUST be filled!\n",
    "            'initial_loss': float(baseline_initial_loss),  # MUST NOT be 0\n",
    "            'final_loss': float(baseline_final_loss),  # MUST NOT be 0\n",
    "            'training_time_seconds': float(baseline_training_time),  # MUST NOT be 0\n",
    "            'loss_decreased': bool(baseline_final_loss < baseline_initial_loss),  # Auto-calculated\n",
    "\n",
    "            # Metrics - Fill based on your problem type\n",
    "            'test_accuracy': float(baseline_acc),\n",
    "            'test_precision': float(baseline_prec),\n",
    "            'test_recall': float(baseline_rec),\n",
    "            'test_f1': float(baseline_f1),\n",
    "            'test_mse': 0.0,\n",
    "            'test_rmse': 0.0,\n",
    "            'test_mae': 0.0,\n",
    "            'test_r2': 0.0,\n",
    "        },\n",
    "\n",
    "        # ===== MLP Model (4 marks) =====\n",
    "        'mlp_model': {\n",
    "            'architecture': [int(x) for x in mlp_architecture],  # MUST have ‚â•3 elements\n",
    "            'n_hidden_layers': int(len(mlp_architecture) - 2) if len(mlp_architecture) > 0 else 0,\n",
    "            'learning_rate': 0.3,\n",
    "            'n_iterations': 1000,\n",
    "\n",
    "            # CRITICAL: These MUST be filled!\n",
    "            'initial_loss': float(mlp_initial_loss),  # MUST NOT be 0\n",
    "            'final_loss': float(mlp_final_loss),  # MUST NOT be 0\n",
    "            'training_time_seconds': float(mlp_training_time),  # MUST NOT be 0\n",
    "            'loss_decreased': bool(mlp_final_loss < mlp_initial_loss),  # Auto-calculated\n",
    "\n",
    "            # Metrics\n",
    "            'test_accuracy': float(mlp_acc),\n",
    "            'test_precision': float(mlp_prec),\n",
    "            'test_recall': float(mlp_rec),\n",
    "            'test_f1': float(mlp_f1),\n",
    "            'test_mse': 0.0,\n",
    "            'test_rmse': 0.0,\n",
    "            'test_mae': 0.0,\n",
    "            'test_r2': 0.0,\n",
    "        },\n",
    "\n",
    "        # ===== Analysis (2 marks) =====\n",
    "        'analysis': analysis_text,\n",
    "        'analysis_word_count': len(analysis_text.split()),\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# ===== CRITICAL: CALL AND PRINT RESULTS =====\n",
    "# This MUST be executed and output MUST be visible!\n",
    "import json\n",
    "results = get_assignment_results()\n",
    "print(json.dumps(results, indent=2))\n",
    "\n",
    "# ===== Validation =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "errors = []\n",
    "\n",
    "if results['n_samples'] < 500:\n",
    "    errors.append(f\"‚ùå Dataset too small: {results['n_samples']} < 500\")\n",
    "if results['n_features'] < 5:\n",
    "    errors.append(f\"‚ùå Too few features: {results['n_features']} < 5\")\n",
    "if results['baseline_model']['initial_loss'] == 0:\n",
    "    errors.append(\"‚ùå Baseline initial_loss is 0\")\n",
    "if results['baseline_model']['final_loss'] == 0:\n",
    "    errors.append(\"‚ùå Baseline final_loss is 0\")\n",
    "if results['baseline_model']['training_time_seconds'] == 0:\n",
    "    errors.append(\"‚ùå Baseline training_time is 0\")\n",
    "if results['mlp_model']['initial_loss'] == 0:\n",
    "    errors.append(\"‚ùå MLP initial_loss is 0\")\n",
    "if results['mlp_model']['final_loss'] == 0:\n",
    "    errors.append(\"‚ùå MLP final_loss is 0\")\n",
    "if results['mlp_model']['training_time_seconds'] == 0:\n",
    "    errors.append(\"‚ùå MLP training_time is 0\")\n",
    "if len(results['mlp_model']['architecture']) < 3:\n",
    "    errors.append(\"‚ùå MLP architecture invalid\")\n",
    "if results['analysis_word_count'] < 200:\n",
    "    errors.append(f\"‚ùå Analysis too short: {results['analysis_word_count']} < 200 words\")\n",
    "\n",
    "if errors:\n",
    "    print(\"ERRORS FOUND:\")\n",
    "    for err in errors:\n",
    "        print(err)\n",
    "    print(\" FIX THESE BEFORE SUBMITTING! \")\n",
    "else:\n",
    "    print(\"‚úÖ All validation checks passed!\")\n",
    "    print(\"‚úÖ Ready to submit!\")\n",
    "    print(\"Next steps:\")\n",
    "    print(\"1. Kernel ‚Üí Restart & Clear Output\")\n",
    "    print(\"2. Kernel ‚Üí Restart & Run All\")\n",
    "    print(\"3. Verify this output is visible\")\n",
    "    print(\"4. Save notebook\")\n",
    "    print(\"5. Rename as: YourStudentID_assignment.ipynb\")\n",
    "    print(\"6. Submit to LMS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPvwotBWBBuh"
   },
   "source": [
    "## Test Your Output\n",
    "\n",
    "Run this cell to verify your results dictionary is complete and properly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4mkH-nSBBui"
   },
   "outputs": [],
   "source": [
    "# Test the output\n",
    "import json\n",
    "\n",
    "try:\n",
    "    results = get_assignment_results()\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"ASSIGNMENT RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(json.dumps(results, indent=2))\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "    # Check for missing values\n",
    "    missing = []\n",
    "    def check_dict(d, prefix=\"\"):\n",
    "        for k, v in d.items():\n",
    "            if isinstance(v, dict):\n",
    "                check_dict(v, f\"{prefix}{k}.\")\n",
    "            elif (v == 0 or v == \"\" or v == 0.0 or v == []) and \\\n",
    "                 k not in ['improvement', 'improvement_percentage', 'baseline_better',\n",
    "                          'baseline_converged', 'mlp_converged', 'total_parameters',\n",
    "                          'test_accuracy', 'test_precision', 'test_recall', 'test_f1',\n",
    "                          'test_mse', 'test_rmse', 'test_mae', 'test_r2']:\n",
    "                missing.append(f\"{prefix}{k}\")\n",
    "\n",
    "    check_dict(results)\n",
    "\n",
    "    if missing:\n",
    "        print(f\"‚ö†Ô∏è  Warning: {len(missing)} fields still need to be filled:\")\n",
    "        for m in missing[:15]:  # Show first 15\n",
    "            print(f\"  - {m}\")\n",
    "        if len(missing) > 15:\n",
    "            print(f\"  ... and {len(missing)-15} more\")\n",
    "    else:\n",
    "        print(\"‚úÖ All required fields are filled!\")\n",
    "        print(\"\\nüéâ You're ready to submit!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"1. Kernel ‚Üí Restart & Clear Output\")\n",
    "        print(\"2. Kernel ‚Üí Restart & Run All\")\n",
    "        print(\"3. Verify no errors\")\n",
    "        print(\"4. Save notebook\")\n",
    "        print(\"5. Rename as: YourStudentID_assignment.ipynb\")\n",
    "        print(\"6. Submit to LMS\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in get_assignment_results(): {str(e)}\")\n",
    "    print(\"\\nPlease fix the errors above before submitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuRKuL80BBui"
   },
   "source": [
    "---\n",
    "\n",
    "## üì§ Before Submitting - Final Checklist\n",
    "\n",
    "- [ ] **All TODO sections completed**\n",
    "- [ ] **Both models implemented from scratch** (no sklearn models!)\n",
    "- [ ] **get_assignment_results() function filled accurately**\n",
    "- [ ] **Loss decreases for both models**\n",
    "- [ ] **Analysis ‚â• 200 words**\n",
    "- [ ] **All cells run without errors** (Restart & Run All)\n",
    "- [ ] **Visualizations created**\n",
    "- [ ] **File renamed correctly**: YourStudentID_assignment.ipynb\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck! **"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
